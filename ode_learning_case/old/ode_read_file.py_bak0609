
## TODO consider set data size in precompute
import os
import argparse
import time
import numpy as np

import torch
import torch.nn as nn
import torch.optim as optim

import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import json

parser = argparse.ArgumentParser('ODE demo')
parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')
#parser.add_argument('--data_size', type=int, default=3000)
parser.add_argument('--batch_time', type=int, default=40)
parser.add_argument('--batch_size', type=int, default=40)
parser.add_argument('--niters', type=int, default=50000)
parser.add_argument('--vc_init_flag', type=int, default=0)
parser.add_argument('--ode_nums', type=int, default=2)
parser.add_argument('--basis_order', type=int, default=3)
parser.add_argument('--lr', type=float, default=0.01)
parser.add_argument('--test_freq', type=int, default=1000)
parser.add_argument('--viz', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
parser.add_argument('--adjoint', action='store_true')
#parser.add_argument('--train_size', type=int, default=2000)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint

device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

equationdata = np.loadtxt('EquationData.txt')
true_y = torch.from_numpy(equationdata[:,1:3].reshape(-1,1,2)).type(torch.FloatTensor)
true_yorig = true_y
true_y0 = true_y[0]
t = torch.from_numpy(equationdata[:,0]).type(torch.FloatTensor)
# Add random white noise
#true_y = torch.max(abs(true_y),0)[0]*0.01*torch.Tensor([np.random.normal(0,1),np.random.normal(0,1)]).view(1,-1) + true_y
true_y = torch.max(abs(true_y),0)[0]*0.01*torch.Tensor(np.random.normal(0,1,list(true_y.size()))) + true_y
# Set data_size and train_size
args.data_size = t.size()[0]
args.train_size = int(args.data_size*0.8)

train_y = true_y[:args.train_size]
test_y = true_y[args.train_size:]


def get_batch(train_size, batch_time):
    #sr = range(train_size-batch_time)
    #s = torch.from_numpy(np.array([np.random.choice(sr[itera*batch_time:(itera+1)*batch_time],1)
    #    for itera in np.arange(int((train_size-batch_time)/batch_time),dtype=np.int64)], dtype=np.int64).reshape(-1))
    s = torch.from_numpy(np.random.choice(np.arange(train_size - batch_time, dtype=np.int64), args.batch_size, replace=False))
    batch_y0 = train_y[s]  # (M, D)
    batch_t = t[:batch_time]  # (T)
    batch_y = torch.stack([true_y[s + i] for i in range(batch_time)], dim=0)  # (T, M, D)
    return batch_y0, batch_t, batch_y


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


if args.viz:
    makedirs('png')
    import matplotlib.pyplot as plt
    fig = plt.figure(figsize=(12, 4), facecolor='white')
    ax_traj = fig.add_subplot(131, frameon=False)
    ax_phase = fig.add_subplot(132, frameon=False)
    ax_vecfield = fig.add_subplot(133, frameon=False)
    #plt.show(block=False)


def visualize(time, true_y, pred_y, odefunc, itr):

    if args.viz:

        ax_traj.cla()
        ax_traj.set_title('Trajectories')
        ax_traj.set_xlabel('t')
        ax_traj.set_ylabel('x,y')
        ax_traj.plot(time.numpy(), true_y.numpy()[:, 0, 0], time.numpy(), true_y.numpy()[:, 0, 1], 'g-')
        ax_traj.plot(time.numpy(), pred_y.numpy()[:, 0, 0], '--', time.numpy(), pred_y.numpy()[:, 0, 1], 'b--')
        ax_traj.set_xlim(time.min(), time.max())
        # ax_traj.set_ylim(-2, 2)
        ax_traj.legend()

        ax_phase.cla()
        ax_phase.set_title('Phase Portrait')
        ax_phase.set_xlabel('x')
        ax_phase.set_ylabel('y')
        ax_phase.plot(true_y.numpy()[:, 0, 0], true_y.numpy()[:, 0, 1], 'g-')
        ax_phase.plot(pred_y.numpy()[:, 0, 0], pred_y.numpy()[:, 0, 1], 'b--')
        # ax_phase.set_xlim(-2, 2)
        # ax_phase.set_ylim(-2, 2)

        ax_vecfield.cla()
        ax_vecfield.set_title('Learned Vector Field')
        ax_vecfield.set_xlabel('x')
        ax_vecfield.set_ylabel('y')

        y, x = np.mgrid[-2:2:21j, -2:2:21j]
        dydt = odefunc(0, torch.Tensor(np.stack([x, y], -1).reshape(21 * 21, 2))).cpu().detach().numpy()
        mag = np.sqrt(dydt[:, 0]**2 + dydt[:, 1]**2).reshape(-1, 1)
        dydt = (dydt / mag)
        dydt = dydt.reshape(21, 21, 2)

        ax_vecfield.streamplot(x, y, dydt[:, :, 0], dydt[:, :, 1], color="black")
        ax_vecfield.set_xlim(-2, 2)
        ax_vecfield.set_ylim(-2, 2)

        fig.tight_layout()
        plt.savefig('png/{:03d}'.format(itr))
        plt.draw()
        #plt.pause(0.001)


class OdeNet(nn.Module):
    def __init__(self, ode_nums, basis_order, vc_init_flag):
        super(OdeNet, self).__init__()
        self._total_basis = int(np.math.factorial(ode_nums+basis_order)\
                /(np.math.factorial(ode_nums)*np.math.factorial(basis_order)))
        self.vc = nn.Parameter(torch.Tensor(self._total_basis,ode_nums))
        self.ode_nums = ode_nums
        self.basis_order = basis_order

        self._vc_init_flag = vc_init_flag
        self.vc.data.uniform_(-0.1, 0.1)
        #self.vc.data[0,:] = 0

    def forward(self, t, input):

        def _compute_theta3d():
            _basis_count = 0
            _Theta = torch.zeros(input.size(0),1,self._total_basis)
            _Theta[:,0,0] = 1
            _basis_count += 1
            for ii in range(0,self.ode_nums):
                _Theta[:,0,_basis_count] = input[:,0,ii]
                _basis_count += 1

            if self.basis_order >= 2:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        _Theta[:,0,_basis_count] = torch.mul(input[:,0,ii],input[:,0,jj])
                        _basis_count += 1

            if self.basis_order >= 3:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            _Theta[:,0,_basis_count] = torch.mul(torch.mul(input[:,0,ii],\
                                input[:,0,jj]),input[:,0,kk])
                            _basis_count += 1

            if self.basis_order >= 4:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                _Theta[:,0,_basis_count] = torch.mul(torch.mul(torch.mul(input[:,0,ii],\
                                    input[:,0,jj]),input[:,0,kk]),input[:,0,ll])
                                _basis_count += 1

            if self.basis_order >= 5:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                for mm in range(ll,self.ode_nums):
                                    _Theta[:,0,_basis_count] = torch.mul(torch.mul(torch.mul(torch.mul(\
                                        input[:,0,ii],input[:,0,jj]),input[:,0,kk]),\
                                            input[:,0,ll]),input[:,0,mm])
                                    _basis_count += 1
            assert _basis_count == self._total_basis
            return _Theta

        def _compute_theta2d():
            _basis_count = 0
            _Theta = torch.zeros(input.size(0),self._total_basis)
            _Theta[:,0] = 1
            _basis_count += 1
            for ii in range(0,self.ode_nums):
                _Theta[:,_basis_count] = input[:,ii]
                _basis_count += 1

            if self.basis_order >= 2:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        _Theta[:,_basis_count] = input[:,ii]*input[:,jj]
                        _basis_count += 1

            if self.basis_order >= 3:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            _Theta[:,_basis_count] = input[:,ii]*input[:,jj]*input[:,kk]
                            _basis_count += 1

            if self.basis_order >= 4:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                _Theta[:,_basis_count] = input[:,ii]*input[:,jj]*input[:,kk]*input[:,ll]
                                _basis_count += 1

            if self.basis_order >= 5:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                for mm in range(ll,self.ode_nums):
                                    _Theta[:,_basis_count] = input[:,ii]*input[:,jj]*\
                                    input[:,kk]*input[:,ll]*input[:,mm]
                                    _basis_count += 1
            assert _basis_count == self._total_basis
            return _Theta

        def _vc_init():
            _left_dxdt = torch.rand(input.size(0),input.size(2))*0.1
            #_left_dxdt = input.reshape(-1,self.ode_nums)
            #_left_dxdt = _left_dxdt - torch.from_numpy(np.roll(_left_dxdt,1,axis=0))
            _Theta_init = _compute_theta3d().reshape(-1,self._total_basis)
            self._vc_init_flag = 1
            return torch.mm(torch.from_numpy(np.linalg.pinv\
                    (_Theta_init)),_left_dxdt)

        if self._vc_init_flag == 0:
            self.vc.data = _vc_init()

        if input.dim() == 2:
            output = torch.mm(_compute_theta2d(),self.vc)
        else:
            output = torch.matmul(_compute_theta3d(),self.vc)
        return output

def saveStateDict(input,itr):
    """A function used to save model.state_dict() OrderedDict as json file with 'matrxi%s.json'%itr
    file name.
    Example: saveStateDict(func.state_dict(), 2) creats matrix2.json in matrix directory.
    """
    input_dict = dict()
    for k,v in input.items():
        input_dict[k] = v.numpy().tolist()
    if not os.path.exists('matrix'):
        os.makedirs('matrix')
    with open('matrix/matrix{}.json'.format(itr), 'w') as fp:
        json.dump(input_dict, fp)

class Shrink(object):

    def __init__(self, threshold):
        self.threshold = threshold

    def __call__(self, module):
        if hasattr(module, 'vc'):
            w = module.vc.data
            #print(module.vc)
            _indexzero = abs(w) < self.threshold
            #print(_indexzero)
            w[_indexzero] = 0
            module.vc.data = w
            for p in module.parameters():
                p.grad[_indexzero] = 0

def adjust_learning_rate(optimizer, itr):
    """Sets the learning rate to the initial LR decayed by 0.5 every 1000 epochs"""
    lr = args.lr * (0.5 ** (itr // 1000))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

def intialize_parameters(func, batch_y, batch_t, ode_nums, basis_order,  vc_init_flag):
    if vc_init_flag == 0:
        pass
    else:
        #batch_y_st = batch_y[0,:,0,:]
        #batch_y_et = batch_y[-1,:,0,:]
        #length_t = batch_t[-1]-batch_t[0]

        _basis_count = 0
        _total_basis = int(np.math.factorial(ode_nums+basis_order)\
            /(np.math.factorial(ode_nums)*np.math.factorial(basis_order)))
        _Theta = torch.zeros(batch_y.size(1),_total_basis)
        _Theta[:,0] = 1
        _basis_count += 1
        for ii in range(0,ode_nums):
            _Theta[:,_basis_count] = batch_y_st[:,ii]
            _basis_count += 1

        if basis_order >= 2:
            for ii in range(0,ode_nums):
                for jj in range(ii,ode_nums):
                    _Theta[:,_basis_count] = batch_y_st[:,ii]*batch_y_st[:,jj]
                    _basis_count += 1

        if basis_order >= 3:
            for ii in range(0,ode_nums):
                for jj in range(ii,ode_nums):
                    for kk in range(jj,ode_nums):
                        _Theta[:,_basis_count] = batch_y_st[:,ii]*batch_y_st[:,jj]*batch_y_st[:,kk]
                        _basis_count += 1

        if basis_order >= 4:
            for ii in range(0,ode_nums):
                for jj in range(ii,ode_nums):
                    for kk in range(jj,ode_nums):
                        for ll in range(kk,ode_nums):
                            _Theta[:,_basis_count] = batch_y_st[:,ii]*batch_y_st[:,jj]\
                                    *batch_y_st[:,kk]*batch_y_st[:,ll]
                            _basis_count += 1

        if basis_order >= 5:
            for ii in range(0,ode_nums):
                for jj in range(ii,ode_nums):
                    for kk in range(jj,ode_nums):
                        for ll in range(kk,ode_nums):
                            for mm in range(ll,ode_nums):
                                _Theta[:,_basis_count] = batch_y_st[:,ii]*batch_y_st[:,jj]*\
                                batch_y_st[:,kk]*batch_y_st[:,ll]*batch_y_st[:,mm]
                                _basis_count += 1
        assert _basis_count == _total_basis

        _left_dxdt = (batch_y_st)/length_t
        func.vc.data = torch.mm(torch.from_numpy(np.linalg.pinv\
                (_Theta)),_left_dxdt)



if __name__ == '__main__':

    ii = 0

    func = OdeNet(args.ode_nums,args.basis_order,args.vc_init_flag)
    func.float()
    shrink = Shrink(0.001)
    w = list(func.parameters())

    #optimizer = optim.RMSprop(func.parameters(), lr=1e-3)
    optimizer = optim.Adam(func.parameters(), lr=args.lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
    end = time.time()

    # The batch structure:
    #--#---#-----#----- batch_y0=[#,#,#]
    #__#*@-#*@---#*@---- batch_y or pred_y = [[#,#,#],[*,*,*],[@,@,@]]
    #Where the number of # is batch_size, the number type of symbols  is batch_time. Here they are 3 both in
    #this scheme.

    for itr in range(1, args.niters + 1):
        optimizer.zero_grad()
        #print(func.vc)
        batch_y0, batch_t, batch_y = get_batch(args.train_size, args.batch_time)
        batch_y0 = batch_y0.type(torch.FloatTensor)
        batch_t = batch_t.type(torch.FloatTensor)
        batch_y = batch_y.type(torch.FloatTensor)
        # if flag = 1, optimize by outer function, elif flag = 0, optimize by inner function
        if itr == 1:
            _, batch_ti, batch_yi = get_batch(args.train_size,10*args.batch_time)
            print(batch_ti.size())
            print(batch_yi.size())
            intialize_parameters(func, batch_yi, batch_ti, args.ode_nums, args.basis_order, args.vc_init_flag)
        pred_y = odeint(func, batch_y0, batch_t)
        loss = torch.mean(torch.abs(pred_y - batch_y))
        l1_regularization = torch.tensor(0).type(torch.FloatTensor)
        reg_loss = 0
        for param in func.parameters():
            l1_regularization += torch.norm(param,1)
        factor = 0.05
        loss += factor * l1_regularization
        loss.backward()
        print(itr)
        if itr > 10 and itr<3000:
            func.apply(shrink)
        print(func.vc)
        adjust_learning_rate(optimizer, itr)
        optimizer.step()

        if itr % args.test_freq == 0:
            with torch.no_grad():
                pred_y = odeint(func, test_y[0], t[len(train_y):])
                loss = torch.mean(torch.abs(pred_y - test_y))
                print('Iter {:04d} | test Loss {:.6f}'.format(itr, loss.item()))
                pred_train = odeint(func, true_y0, t[:len(train_y)])
                loss_train = torch.mean(torch.abs(pred_train - train_y))
                print('Iter {:04d} | train Loss {:.6f}'.format(itr, loss_train.item()))

                visualize(t[:len(train_y)], train_y, pred_train, func, ii)

                #pred_all_y = odeint(func, true_y0, t)
                #visualize(t, true_y, pred_all_y, func, ii)
                #visualize(t, true_y, pred_all_y, func, ii)

                ii += 1

                print('Learning iteration is: ', w)
                #Write the parameters to json file
                saveStateDict(func.state_dict(),itr)
        end = time.time()


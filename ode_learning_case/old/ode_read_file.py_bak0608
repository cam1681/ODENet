
## TODO consider set data size in precompute
import os
import argparse
import time
import numpy as np

import torch
import torch.nn as nn
import torch.optim as optim

import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import json

parser = argparse.ArgumentParser('ODE demo')
parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')
#parser.add_argument('--data_size', type=int, default=3000)
parser.add_argument('--batch_time', type=int, default=30)
parser.add_argument('--batch_size', type=int, default=30)
parser.add_argument('--niters', type=int, default=50000)
parser.add_argument('--test_freq', type=int, default=1000)
parser.add_argument('--viz', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
parser.add_argument('--adjoint', action='store_true')
#parser.add_argument('--train_size', type=int, default=2000)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint

device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

equationdata = np.loadtxt('EquationData.txt')
true_y = torch.from_numpy(equationdata[:,1:3].reshape(-1,1,2)).type(torch.FloatTensor)
true_yorig = true_y
true_y0 = true_y[0]
t = torch.from_numpy(equationdata[:,0]).type(torch.FloatTensor)
# Add random white noise
#true_y = torch.max(abs(true_y),0)[0]*0.01*torch.Tensor([np.random.normal(0,1),np.random.normal(0,1)]).view(1,-1) + true_y
true_y = torch.max(abs(true_y),0)[0]*0.01*torch.Tensor(np.random.normal(0,1,list(true_y.size()))) + true_y
# Set data_size and train_size
args.data_size = t.size()[0]
args.train_size = int(args.data_size*0.8)

train_y = true_y[:args.train_size]
test_y = true_y[args.train_size:]


def get_batch():
    #sr = range(args.train_size-args.batch_time)
    #s = torch.from_numpy(np.array([np.random.choice(sr[itera*args.batch_time:(itera+1)*args.batch_time],1)
    #    for itera in np.arange(int((args.train_size-args.batch_time)/args.batch_time),dtype=np.int64)], dtype=np.int64).reshape(-1))
    s = torch.from_numpy(np.random.choice(np.arange(args.train_size - args.batch_time, dtype=np.int64), args.batch_size, replace=False))
    batch_y0 = train_y[s]  # (M, D)
    batch_t = t[:args.batch_time]  # (T)
    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=0)  # (T, M, D)
    return batch_y0, batch_t, batch_y


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


if args.viz:
    makedirs('png')
    import matplotlib.pyplot as plt
    fig = plt.figure(figsize=(12, 4), facecolor='white')
    ax_traj = fig.add_subplot(131, frameon=False)
    ax_phase = fig.add_subplot(132, frameon=False)
    ax_vecfield = fig.add_subplot(133, frameon=False)
    #plt.show(block=False)


def visualize(time, true_y, pred_y, odefunc, itr):

    if args.viz:

        ax_traj.cla()
        ax_traj.set_title('Trajectories')
        ax_traj.set_xlabel('t')
        ax_traj.set_ylabel('x,y')
        ax_traj.plot(time.numpy(), true_y.numpy()[:, 0, 0], time.numpy(), true_y.numpy()[:, 0, 1], 'g-')
        ax_traj.plot(time.numpy(), pred_y.numpy()[:, 0, 0], '--', time.numpy(), pred_y.numpy()[:, 0, 1], 'b--')
        ax_traj.set_xlim(time.min(), time.max())
        # ax_traj.set_ylim(-2, 2)
        ax_traj.legend()

        ax_phase.cla()
        ax_phase.set_title('Phase Portrait')
        ax_phase.set_xlabel('x')
        ax_phase.set_ylabel('y')
        ax_phase.plot(true_y.numpy()[:, 0, 0], true_y.numpy()[:, 0, 1], 'g-')
        ax_phase.plot(pred_y.numpy()[:, 0, 0], pred_y.numpy()[:, 0, 1], 'b--')
        # ax_phase.set_xlim(-2, 2)
        # ax_phase.set_ylim(-2, 2)

        ax_vecfield.cla()
        ax_vecfield.set_title('Learned Vector Field')
        ax_vecfield.set_xlabel('x')
        ax_vecfield.set_ylabel('y')

        y, x = np.mgrid[-2:2:21j, -2:2:21j]
        dydt = odefunc(0, torch.Tensor(np.stack([x, y], -1).reshape(21 * 21, 2))).cpu().detach().numpy()
        mag = np.sqrt(dydt[:, 0]**2 + dydt[:, 1]**2).reshape(-1, 1)
        dydt = (dydt / mag)
        dydt = dydt.reshape(21, 21, 2)

        ax_vecfield.streamplot(x, y, dydt[:, :, 0], dydt[:, :, 1], color="black")
        ax_vecfield.set_xlim(-2, 2)
        ax_vecfield.set_ylim(-2, 2)

        fig.tight_layout()
        plt.savefig('png/{:03d}'.format(itr))
        plt.draw()
        #plt.pause(0.001)


class OdeNet(nn.Module):
    def __init__(self, ode_nums, basis_order):
        super(OdeNet, self).__init__()
        self._total_basis = int(np.math.factorial(ode_nums+basis_order)\
                /(np.math.factorial(ode_nums)*np.math.factorial(basis_order)))
        self.vc = nn.Parameter(torch.Tensor(self._total_basis,ode_nums))
        self.ode_nums = ode_nums
        self.basis_order = basis_order

        self.vc.data.uniform_(-0.1, 0.1)
        self.vc.data[0,:] = 0

    def forward(self, t, input):

        def compute_theta3d():
            _basis_count = 0
            Theta = torch.zeros(input.size(0),1,self._total_basis)
            Theta[:,0,0] = 1
            _basis_count += 1
            for ii in range(0,self.ode_nums):
                Theta[:,0,_basis_count] = input[:,0,ii]
                _basis_count += 1

            if self.basis_order >= 2:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        Theta[:,0,_basis_count] = torch.mul(input[:,0,ii],input[:,0,jj])
                        _basis_count += 1

            if self.basis_order >= 3:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            Theta[:,0,_basis_count] = torch.mul(torch.mul(input[:,0,ii],\
                                input[:,0,jj]),input[:,0,kk])
                            _basis_count += 1

            if self.basis_order >= 4:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                Theta[:,0,_basis_count] = torch.mul(torch.mul(torch.mul(input[:,0,ii],\
                                    input[:,0,jj]),input[:,0,kk]),input[:,0,ll])
                                _basis_count += 1

            if self.basis_order >= 5:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                for mm in range(ll,self.ode_nums):
                                    Theta[:,0,_basis_count] = torch.mul(torch.mul(torch.mul(torch.mul(\
                                        input[:,0,ii],input[:,0,jj]),input[:,0,kk]),\
                                            input[:,0,ll]),input[:,0,mm])
                                    _basis_count += 1
            assert _basis_count == self._total_basis

            return Theta

        def compute_theta2d():
            _basis_count = 0
            Theta = torch.zeros(input.size(0),self._total_basis)
            Theta[:,0] = 1
            _basis_count += 1
            for ii in range(0,self.ode_nums):
                Theta[:,_basis_count] = input[:,ii]
                _basis_count += 1

            if self.basis_order >= 2:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        Theta[:,_basis_count] = input[:,ii]*input[:,jj]
                        _basis_count += 1

            if self.basis_order >= 3:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            Theta[:,_basis_count] = input[:,ii]*input[:,jj]*input[:,kk]
                            _basis_count += 1

            if self.basis_order >= 4:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                Theta[:,_basis_count] = input[:,ii]*input[:,jj]*input[:,kk]*input[:,ll]
                                _basis_count += 1

            if self.basis_order >= 5:
                for ii in range(0,self.ode_nums):
                    for jj in range(ii,self.ode_nums):
                        for kk in range(jj,self.ode_nums):
                            for ll in range(kk,self.ode_nums):
                                for mm in range(ll,self.ode_nums):
                                    Theta[:,_basis_count] = input[:,ii]*input[:,jj]*\
                                    input[:,kk]*input[:,ll]*input[:,mm]
                                    _basis_count += 1
            assert _basis_count == self._total_basis

            return Theta

        if input.dim() == 2:
            output = torch.mm(compute_theta2d(),self.vc)
        else:
            output = torch.matmul(compute_theta3d(),self.vc)
        return output

def saveStateDict(input,itr):
    """A function used to save model.state_dict() OrderedDict as json file with 'matrxi%s.json'%itr
    file name.
    Example: saveStateDict(func.state_dict(), 2) creats matrix2.json in matrix directory.
    """
    input_dict = dict()
    for k,v in input.items():
        input_dict[k] = v.numpy().tolist()
    if not os.path.exists('matrix'):
        os.makedirs('matrix')
    with open('matrix/matrix{}.json'.format(itr), 'w') as fp:
        json.dump(input_dict, fp)

class Shrink(object):

    def __init__(self, threshold):
        self.threshold = threshold

    def __call__(self, module):
        if hasattr(module, 'vc'):
            w = module.vc.data
            print(module.vc)
            _indexzero = abs(w) < self.threshold
            #print(_indexzero)
            w[_indexzero] = 0
            module.vc.data = w
            for p in module.parameters():
                p.grad[_indexzero] = 0
            print(module.vc)




if __name__ == '__main__':

    ii = 0

    func = OdeNet(2,2)
    func.float()
    shrink = Shrink(0.001)
    w = list(func.parameters())

    #optimizer = optim.RMSprop(func.parameters(), lr=1e-3)
    optimizer = optim.Adam(func.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
    end = time.time()

    # The batch structure:
    #--#---#-----#----- batch_y0=[#,#,#]
    #__#*@-#*@---#*@---- batch_y or pred_y = [[#,#,#],[*,*,*],[@,@,@]]
    #Where the number of # is batch_size, the number type of symbols  is batch_time. Here they are 3 both in
    #this scheme.

    for itr in range(1, args.niters + 1):
        #print(func.vc)
        optimizer.zero_grad()
        batch_y0, batch_t, batch_y = get_batch()
        batch_y0 = batch_y0.type(torch.FloatTensor)
        batch_t = batch_t.type(torch.FloatTensor)
        batch_y = batch_y.type(torch.FloatTensor)
        pred_y = odeint(func, batch_y0, batch_t)
        loss = torch.mean(torch.abs(pred_y - batch_y))
        l1_regularization = torch.tensor(0).type(torch.FloatTensor)
        reg_loss = 0
        for param in func.parameters():
            l1_regularization += torch.norm(param,1)
        factor = 0.05
        loss += factor * l1_regularization
        loss.backward()
        print(itr)
        if itr > 100:
            func.apply(shrink)
        optimizer.step()

        if itr % args.test_freq == 0:
            with torch.no_grad():
                pred_y = odeint(func, test_y[0], t[len(train_y):])
                loss = torch.mean(torch.abs(pred_y - test_y))
                print('Iter {:04d} | test Loss {:.6f}'.format(itr, loss.item()))
                pred_train = odeint(func, true_y0, t[:len(train_y)])
                loss_train = torch.mean(torch.abs(pred_train - train_y))
                print('Iter {:04d} | train Loss {:.6f}'.format(itr, loss_train.item()))

                visualize(t[:len(train_y)], train_y, pred_train, func, ii)

                #pred_all_y = odeint(func, true_y0, t)
                #visualize(t, true_y, pred_all_y, func, ii)
                #visualize(t, true_y, pred_all_y, func, ii)

                ii += 1

                print('Learning iteration is: ', w)
                #Write the parameters to json file
                saveStateDict(func.state_dict(),itr)
        end = time.time()

